{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1), (5, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5, 1)\n",
    "t_data = np.array([2,3,4,5,6]).reshape(5, 1)\n",
    "x_data.shape, t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1), (5, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = [[1,2],[2,3],[3,4],[4,5],[5,6]]\n",
    "x_data = np.array(raw_data)[:,0].reshape(-1,1)\n",
    "t_data = np.array(raw_data)[:,1].reshape(-1,1)\n",
    "x_data.shape, t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11734211]]), 2, array([0.62295256]), 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "W, W.ndim, b, b.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t - y)**2) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t - y)**2) / len(x)\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error vlaue = 10.708922601322943\n",
      "Initial W = [[0.11734211]]\n",
      "Initial b = [0.62295256]\n",
      "\n",
      "step = 0 Initial error vlaue = 6.302137434258 Initial W = [[0.33414969]] Initial b = [0.67044452]\n",
      "\n",
      "step = 400 Initial error vlaue = 0.0003564045666919776 Initial W = [[1.01225938]] Initial b = [0.9557506]\n",
      "\n",
      "step = 800 Initial error vlaue = 2.2740718409063435e-05 Initial W = [[1.0030967]] Initial b = [0.98882267]\n",
      "\n",
      "step = 1200 Initial error vlaue = 1.4509922770083706e-06 Initial W = [[1.00078222]] Initial b = [0.99717663]\n",
      "\n",
      "step = 1600 Initial error vlaue = 9.258188549997023e-08 Initial W = [[1.00019759]] Initial b = [0.99928682]\n",
      "\n",
      "step = 2000 Initial error vlaue = 5.907271636450529e-09 Initial W = [[1.00004991]] Initial b = [0.99981985]\n",
      "\n",
      "step = 2400 Initial error vlaue = 3.769188540379714e-10 Initial W = [[1.00001261]] Initial b = [0.99995449]\n",
      "\n",
      "step = 2800 Initial error vlaue = 2.4049651223040295e-11 Initial W = [[1.00000318]] Initial b = [0.99998851]\n",
      "\n",
      "step = 3200 Initial error vlaue = 1.5345099294767076e-12 Initial W = [[1.0000008]] Initial b = [0.9999971]\n",
      "\n",
      "step = 3600 Initial error vlaue = 9.791080546991179e-14 Initial W = [[1.0000002]] Initial b = [0.99999927]\n",
      "\n",
      "step = 4000 Initial error vlaue = 6.2472882093316535e-15 Initial W = [[1.00000005]] Initial b = [0.99999981]\n",
      "\n",
      "step = 4400 Initial error vlaue = 3.9861392271167117e-16 Initial W = [[1.00000001]] Initial b = [0.99999995]\n",
      "\n",
      "step = 4800 Initial error vlaue = 2.543392528469681e-17 Initial W = [[1.]] Initial b = [0.99999999]\n",
      "\n",
      "step = 5200 Initial error vlaue = 1.622834878640314e-18 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 5600 Initial error vlaue = 1.0354642687505347e-19 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 6000 Initial error vlaue = 6.60684263833593e-21 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 6400 Initial error vlaue = 4.215474513768151e-22 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 6800 Initial error vlaue = 2.6902111951321716e-23 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 7200 Initial error vlaue = 1.717324394914542e-24 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 7600 Initial error vlaue = 1.1007406139742124e-25 Initial W = [[1.]] Initial b = [1.]\n",
      "\n",
      "step = 8000 Initial error vlaue = 7.096001057689306e-27 Initial W = [[1.]] Initial b = [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print('Initial error vlaue =', error_val(x_data, t_data))\n",
    "print('Initial W =', W)\n",
    "print('Initial b =', b)\n",
    "\n",
    "for step in range(8001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print()\n",
    "        print('step =', step, end=' ')\n",
    "        print('Initial error vlaue =', error_val(x_data, t_data), end=' ')\n",
    "        print('Initial W =', W, end=' ')\n",
    "        print('Initial b =', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 3), (25, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data = np.loadtxt('data-01.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[:,:-1]\n",
    "t_data = loaded_data[:, [-1]]\n",
    "\n",
    "x_data.shape, t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.30627725],\n",
       "        [0.06735405],\n",
       "        [0.09510872]]),\n",
       " array([0.27364126]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.rand(3,1)\n",
    "b = np.random.rand(1)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t-y)**2)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t - y)**2) / len(x)\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error vlaue = 15823.217788547923\n",
      "Initial W = [[0.30627724932899236], [0.06735405439420028], [0.0951087209384397]]\n",
      "Initial b = [0.27364126]\n",
      "\n",
      "step = 0 Initial error vlaue = 5859.058851234886 Initial W = [[0.5070783594537499], [0.26931025374922724], [0.3020302668132146]] Initial b = [0.27515471]\n",
      "\n",
      "step = 100000 Initial error vlaue = 6.118532688889288 Initial W = [[0.3559856536523826], [0.530047141268843], [1.1260811731146625]] Initial b = [0.10732786]\n",
      "\n",
      "step = 200000 Initial error vlaue = 6.090272523674057 Initial W = [[0.3559838592239852], [0.5305189311170605], [1.1276458992263072]] Initial b = [-0.06076304]\n",
      "\n",
      "step = 300000 Initial error vlaue = 6.064110029468866 Initial W = [[0.35598213268325174], [0.5309728735832939], [1.1291514331769634]] Initial b = [-0.22249522]\n",
      "\n",
      "step = 400000 Initial error vlaue = 6.039889502170983 Initial W = [[0.3559804714559982], [0.53140964382115], [1.130600014154488]] Initial b = [-0.37810922]\n",
      "\n",
      "step = 500000 Initial error vlaue = 6.017466795146734 Initial W = [[0.355978873071392], [0.5318298914401477], [1.1319937966380371]] Initial b = [-0.52783648]\n",
      "\n",
      "step = 600000 Initial error vlaue = 5.996708461353611 Initial W = [[0.3559773351522507], [0.5322342414759174], [1.1333348536043892]] Initial b = [-0.6718997]\n",
      "\n",
      "step = 700000 Initial error vlaue = 5.977490959140243 Initial W = [[0.3559758554111343], [0.5326232953195046], [1.1346251796117313]] Initial b = [-0.81051314]\n",
      "\n",
      "step = 800000 Initial error vlaue = 5.959699916997845 Initial W = [[0.35597443164735404], [0.5329976316118368], [1.1358666937657789]] Initial b = [-0.94388296]\n",
      "\n",
      "step = 900000 Initial error vlaue = 5.943229452886611 Initial W = [[0.35597306174320764], [0.5333578071044339], [1.1370612425744295]] Initial b = [-1.07220752]\n",
      "\n",
      "step = 1000000 Initial error vlaue = 5.927981544086886 Initial W = [[0.35597174366131856], [0.5337043574874557], [1.1382106026936336]] Initial b = [-1.19567768]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print('Initial error vlaue =', error_val(x_data, t_data))\n",
    "print('Initial W =', W.tolist())\n",
    "print('Initial b =', b)\n",
    "\n",
    "for step in range(1000001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 100000 == 0):\n",
    "        print()\n",
    "        print('step =', step, end=' ')\n",
    "        print('Initial error vlaue =', error_val(x_data, t_data), end=' ')\n",
    "        print('Initial W =', W.tolist(), end=' ')\n",
    "        print('Initial b =', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201.59299271])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([100,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.19865751])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([50,50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf9fd2bd88>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(loaded_data)\n",
    "df.plot.scatter(x=1,y=2,c=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('소비자물가지수_2015100__20200731115319.csv', encoding='cp949', index_col=0).T\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('연간지표_20200731115525.csv', encoding='cp949', index_col=0).iloc[[0],:].T\n",
    "df2 = df2.astype('float')\n",
    "df2['국민총소득(명목, 원화표시) (십억원)'] = df2['국민총소득(명목, 원화표시) (십억원)']/1663206.60*100\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55, 1), (55, 1), dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = np.array(df1['전국']).reshape(-1,1)\n",
    "t_data = np.array(df2['국민총소득(명목, 원화표시) (십억원)']).reshape(-1,1)\n",
    "\n",
    "x_data.shape, t_data.shape, x_data.dtype, t_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.752],\n",
       "        [  3.062],\n",
       "        [  3.396],\n",
       "        [  3.761],\n",
       "        [  4.227],\n",
       "        [  4.902],\n",
       "        [  5.564],\n",
       "        [  6.214],\n",
       "        [  6.414],\n",
       "        [  7.973],\n",
       "        [  9.986],\n",
       "        [ 11.517],\n",
       "        [ 12.68 ],\n",
       "        [ 14.513],\n",
       "        [ 17.173],\n",
       "        [ 22.101],\n",
       "        [ 26.82 ],\n",
       "        [ 28.748],\n",
       "        [ 29.732],\n",
       "        [ 30.408],\n",
       "        [ 31.156],\n",
       "        [ 32.013],\n",
       "        [ 32.989],\n",
       "        [ 35.346],\n",
       "        [ 37.361],\n",
       "        [ 40.564],\n",
       "        [ 44.35 ],\n",
       "        [ 47.106],\n",
       "        [ 49.367],\n",
       "        [ 52.46 ],\n",
       "        [ 54.811],\n",
       "        [ 57.51 ],\n",
       "        [ 60.063],\n",
       "        [ 64.576],\n",
       "        [ 65.101],\n",
       "        [ 66.572],\n",
       "        [ 69.279],\n",
       "        [ 71.193],\n",
       "        [ 73.695],\n",
       "        [ 76.341],\n",
       "        [ 78.444],\n",
       "        [ 80.202],\n",
       "        [ 82.235],\n",
       "        [ 86.079],\n",
       "        [ 88.452],\n",
       "        [ 91.051],\n",
       "        [ 94.717],\n",
       "        [ 96.789],\n",
       "        [ 98.048],\n",
       "        [ 99.298],\n",
       "        [100.   ],\n",
       "        [100.97 ],\n",
       "        [102.93 ],\n",
       "        [104.45 ],\n",
       "        [104.85 ]]),\n",
       " array([[5.06912370e-02],\n",
       "        [6.54771331e-02],\n",
       "        [8.13993884e-02],\n",
       "        [1.04597348e-01],\n",
       "        [1.36472522e-01],\n",
       "        [1.71199417e-01],\n",
       "        [2.08290419e-01],\n",
       "        [2.57153862e-01],\n",
       "        [3.32652600e-01],\n",
       "        [4.76994259e-01],\n",
       "        [6.28803421e-01],\n",
       "        [8.66320516e-01],\n",
       "        [1.11561005e+00],\n",
       "        [1.51679894e+00],\n",
       "        [1.94479146e+00],\n",
       "        [2.36672942e+00],\n",
       "        [2.94569538e+00],\n",
       "        [3.41249848e+00],\n",
       "        [4.05061524e+00],\n",
       "        [4.65844712e+00],\n",
       "        [5.18259127e+00],\n",
       "        [6.05890453e+00],\n",
       "        [7.22843452e+00],\n",
       "        [8.70992215e+00],\n",
       "        [9.93948076e+00],\n",
       "        [1.20463267e+01],\n",
       "        [1.45643061e+01],\n",
       "        [1.66649531e+01],\n",
       "        [1.89249129e+01],\n",
       "        [2.23396600e+01],\n",
       "        [2.61774334e+01],\n",
       "        [2.94088179e+01],\n",
       "        [3.24127381e+01],\n",
       "        [3.18819201e+01],\n",
       "        [3.51687758e+01],\n",
       "        [3.89172458e+01],\n",
       "        [4.22218382e+01],\n",
       "        [4.70073171e+01],\n",
       "        [5.01707485e+01],\n",
       "        [5.45250782e+01],\n",
       "        [5.71597900e+01],\n",
       "        [6.02850361e+01],\n",
       "        [6.53495062e+01],\n",
       "        [6.94146897e+01],\n",
       "        [7.23590082e+01],\n",
       "        [7.96405510e+01],\n",
       "        [8.40265304e+01],\n",
       "        [8.74918546e+01],\n",
       "        [9.08116226e+01],\n",
       "        [9.44256294e+01],\n",
       "        [1.00000000e+02],\n",
       "        [1.05046691e+02],\n",
       "        [1.10820923e+02],\n",
       "        [1.14588140e+02],\n",
       "        [1.16384525e+02]]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data, t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t-y)**2)/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    return np.sum((t - y)**2) / len(x)\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x, W) + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.45482838]]), array([0.24055561]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error vlaue = 636.1988422999273\n",
      "Initial W = [[0.454828384259659]]\n",
      "Initial b = [0.24055561]\n",
      "step = 0 Initial error vlaue = 267.8320396131044 Initial W = [[0.6950855026678397]] Initial b = [0.24032753]\n",
      "step = 10000 Initial error vlaue = 164.91073678022548 Initial W = [[0.9012971056959629]] Initial b = [-8.12916147]\n",
      "step = 20000 Initial error vlaue = 144.9950528546603 Initial W = [[0.9613199853510139]] Initial b = [-12.5167262]\n",
      "step = 30000 Initial error vlaue = 139.52226723017023 Initial W = [[0.9927846735935077]] Initial b = [-14.81673842]\n",
      "step = 40000 Initial error vlaue = 138.0183579191403 Initial W = [[1.009278827354126]] Initial b = [-16.02243144]\n",
      "step = 50000 Initial error vlaue = 137.60508698711288 Initial W = [[1.0179252536651149]] Initial b = [-16.65446968]\n",
      "step = 60000 Initial error vlaue = 137.49152105464634 Initial W = [[1.0224578104143405]] Initial b = [-16.98579144]\n",
      "step = 70000 Initial error vlaue = 137.4603133891257 Initial W = [[1.02483382912381]] Initial b = [-17.15947414]\n",
      "step = 80000 Initial error vlaue = 137.451737592089 Initial W = [[1.0260793656322733]] Initial b = [-17.25052063]\n",
      "step = 90000 Initial error vlaue = 137.44938098214797 Initial W = [[1.0267322902863356]] Initial b = [-17.29824824]\n",
      "step = 100000 Initial error vlaue = 137.448733390981 Initial W = [[1.0270745609471732]] Initial b = [-17.32326762]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print('Initial error vlaue =', error_val(x_data, t_data))\n",
    "print('Initial W =', W.tolist())\n",
    "print('Initial b =', b)\n",
    "\n",
    "for step in range(100001):\n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 10000 == 0):\n",
    "#         print()\n",
    "        print('step =', step, end=' ')\n",
    "        print('Initial error vlaue =', error_val(x_data, t_data), end=' ')\n",
    "        print('Initial W =', W.tolist(), end=' ')\n",
    "        print('Initial b =', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85.38418848]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
